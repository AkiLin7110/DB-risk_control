{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from tqdm  import tqdm\n",
    "headers = {\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 所公告的研發計畫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = 7\n",
    "plans1 = []\n",
    "for i in range(1,end):\n",
    "    res = requests.get(f'https://tiip.itnet.org.tw/news_list.php?m=1&page={i}')\n",
    "\n",
    "    soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "    # Find all rows in the table\n",
    "    rows = soup.find_all(\"tr\")[2:]  # Skip the header row\n",
    "\n",
    "    # Extract the necessary information: 公佈時間, 標題, and URL\n",
    "    for row in rows:\n",
    "        columns = row.find_all(\"td\")\n",
    "        pub_date = columns[1].text.strip()\n",
    "        title = columns[2].text.strip()\n",
    "        link = 'https://tiip.itnet.org.tw/'+columns[2].find(\"a\")[\"href\"]\n",
    "        plans1.append({\"公佈時間\": pub_date, \"標題\": title, \"連結\": link})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 所有核定名單"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''version1'''\n",
    "# end = 7\n",
    "# plans2 = []\n",
    "# for i in range(1,end):\n",
    "#     res = requests.get(f'https://tiip.itnet.org.tw/news_list.php?m=3&page={i}')\n",
    "\n",
    "#     # soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "#     # Parse the HTML content using BeautifulSoup\n",
    "#     soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "#     # Find all rows in the table\n",
    "#     rows = soup.find_all(\"tr\")[2:]  # Skip the header row\n",
    "\n",
    "#     # Extract the necessary information: 公佈時間, 標題, and URL\n",
    "#     for row in rows:\n",
    "#         columns = row.find_all(\"td\")\n",
    "#         pub_date = columns[1].text.strip()\n",
    "#         title = columns[2].text.strip()\n",
    "#         link = 'https://tiip.itnet.org.tw/'+columns[2].find(\"a\")[\"href\"]\n",
    "#         plans2.append({\"公佈時間\": pub_date, \"標題\": title, \"連結\": link})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [02:08<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "# '''version2'''\n",
    "end = 90\n",
    "plans2 = []\n",
    "for i in tqdm(range(1,end)):\n",
    "    try:\n",
    "        res = requests.get(f'https://tiip.itnet.org.tw/achievementList.php?year=&kw=&page={i}')\n",
    "    except:\n",
    "        break\n",
    "\n",
    "    # soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "    # Find all rows in the table\n",
    "    rows = soup.find_all(\"tr\")[2:]  # Skip the header row\n",
    "\n",
    "    # Extract the necessary information: 公佈時間, 標題, and URL\n",
    "    for row in rows:\n",
    "        columns = row.find_all(\"td\")\n",
    "        company_name = columns[2].text.strip()\n",
    "        plans_name = columns[3].text.strip()\n",
    "        date = columns[4].text.strip()\n",
    "        # link = 'https://tiip.itnet.org.tw/'+columns[2].find(\"a\")[\"href\"]\n",
    "        plans2.append({\"公司名稱\": company_name, \"計畫名稱\": plans_name, \"核定日期\": date})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各計畫核定公司"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plans2 = pd.DataFrame(plans2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plans = []\n",
    "for i in tqdm(range(0,len(plans2))):    \n",
    "    res = requests.post(plans2['連結'][i])\n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "\n",
    "    # 計畫類別\n",
    "    plans_type = soup.find_all('title')[0].text\n",
    "    # Extract the company names from the table\n",
    "    rows = soup.find_all(\"tr\")[2:]  # Skip the header row\n",
    "    for row in rows:\n",
    "        columns = row.find_all(\"td\")\n",
    "        company_name = columns[2].text.strip()\n",
    "        plans_name = columns[3].text.strip()\n",
    "        date = columns[4].text.strip()\n",
    "        plans.append({\"計畫類別\": plans_type,\"公司名稱\": company_name, \"計畫名稱\": plans_name, \"核定日期\": date})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(plans)\n",
    "tmp.to_excel('4_政府推動計畫名單.xlsx', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anue",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
